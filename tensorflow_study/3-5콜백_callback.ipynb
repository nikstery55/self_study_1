{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790b400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "콜백은 모델을 훈련할 때 보조적인 작업을 수행할 수 있도록 도와주는 객체\n",
    "모델을 훈련할 때 사용하는 fit()메소드에 callbacks 매개변수로 지정할 수 있다.\n",
    "tensorflow,keras,callbacks 패키지 내 다양한 콜백이 정의되어 있다\n",
    "이중 가장 많이 활용하는 콜백 함수 몇가지를 소개\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "#ㅔ라스의 내장 데이터셋에서 mnist 데이터셋 로드\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ecff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_data()로 데이터셋 로드\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 데이터 정규화\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "# 모델정의 \n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    # 노드=10개가 되어야 한다\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aadda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 컴파일\n",
    "model.compile(optimizer = \"adam\", loss=\"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de02f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#모델 체크 포인트\n",
    "모델 체크포인트는 가장 많이 활용되는 콜백이다. 모델 훈련 시 콜백으로 지정해 줄 수 있으며\n",
    "epoch별 모델의 가중치를 저장한다. 저장할 때 마치 체크포인트를 생성하듯 미리 정해 놓은 규칙에\n",
    "의하여 체크포인트를 생성하고 저장한다\n",
    "\n",
    "주요 하이퍼파라미터에 대한 세부 내용은 다음과 같다\n",
    "\n",
    "filepath : 체크포인트의 저장 경로 지정\n",
    "save_weights_only : 가중치만 저장할지 여부 설정\n",
    "save_best_only : monitor 기준으로 가장 높은 epoch만 저장할지 아니면 매 epoch별 저장할지 여부를 결정\n",
    "monitor : 저장시 기준이 되는 지표 설정 \"val_loss\"로 지정시 검증 손실이 가장 낮은 epoch 의 가중치를 저장\n",
    "verbose : 1로 설정 시 매 epoch 별 저장 여부를 알려주는 로그 메세지 출력\n",
    "\"\"\"\n",
    "# 체크포인트 설정\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = \"tmp_checkpoint.ckpt\",\n",
    "                                               save_weights_only = True,\n",
    "                                               save_best_only = True,\n",
    "                                               monitor = \"val_loss\",\n",
    "                                               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23374776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2314 - accuracy: 0.9303 ETA: 0s - loss:\n",
      "Epoch 00001: val_loss improved from inf to 0.10790, saving model to tmp_checkpoint.ckpt\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.2314 - accuracy: 0.9303 - val_loss: 0.1079 - val_accuracy: 0.9666\n",
      "Epoch 2/10\n",
      "1864/1875 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9715\n",
      "Epoch 00002: val_loss improved from 0.10790 to 0.08653, saving model to tmp_checkpoint.ckpt\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0931 - accuracy: 0.9715 - val_loss: 0.0865 - val_accuracy: 0.9735\n",
      "Epoch 3/10\n",
      "1866/1875 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9792\n",
      "Epoch 00003: val_loss improved from 0.08653 to 0.07534, saving model to tmp_checkpoint.ckpt\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0638 - accuracy: 0.9793 - val_loss: 0.0753 - val_accuracy: 0.9762\n",
      "Epoch 4/10\n",
      "1865/1875 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9843\n",
      "Epoch 00004: val_loss improved from 0.07534 to 0.06953, saving model to tmp_checkpoint.ckpt\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0485 - accuracy: 0.9843 - val_loss: 0.0695 - val_accuracy: 0.9787\n",
      "Epoch 5/10\n",
      "1866/1875 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9873\n",
      "Epoch 00005: val_loss did not improve from 0.06953\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0387 - accuracy: 0.9873 - val_loss: 0.1018 - val_accuracy: 0.9717\n",
      "Epoch 6/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9900\n",
      "Epoch 00006: val_loss did not improve from 0.06953\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.0911 - val_accuracy: 0.9747\n",
      "Epoch 7/10\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9916\n",
      "Epoch 00007: val_loss did not improve from 0.06953\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.0890 - val_accuracy: 0.9762\n",
      "Epoch 8/10\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9923\n",
      "Epoch 00008: val_loss did not improve from 0.06953\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0930 - val_accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9932\n",
      "Epoch 00009: val_loss did not improve from 0.06953\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.0779 - val_accuracy: 0.9801\n",
      "Epoch 10/10\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9932\n",
      "Epoch 00010: val_loss did not improve from 0.06953\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0925 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba90824d00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "모델 체크포인트 객체를 생성후 모델 훈련시 callbacks 매개변수에 지정하면 된다\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train,\n",
    "         validation_data=(x_test,y_test),\n",
    "         epochs=10,\n",
    "         callbacks=[checkpoint]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb34613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0925 - accuracy: 0.9783\n",
      "체크포인트 로드전 : loss: 0.092537, acc0.978300\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9787\n",
      "체크포인트 로드후 : loss: 0.069532, acc0.978700\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#모델 체크포인트\n",
    "매 epoch 마다 모델 체크포인트의 저장 여부를 알려주는 로그 메세지가 출력되며,\n",
    "가장 검증 손실이 낮았던 epoch일 때의 가중치가 현재 모델 체크포인트에\n",
    "저장되었음을 알 수 있다\n",
    "\n",
    "저장한 가중치를 model 인스턴스에 적용하려면, load_weights()메소드에 모델 체크포인트 파일\n",
    "경로를 지정하여 호출해 주어야 한다 이처럼 모델에 저장한 가중치를 명시적으로 로드해주어야\n",
    "검증 손실이 가장 낮았던 가중치가 모델에 로드된다. 이렇게 명시적으로 호출하지 않으면 \n",
    "훈련이 완료되더라고 가중치가 로드되지 않음에 유의한다\n",
    "\"\"\"\n",
    "# 모델 체크포인트 로드전 \n",
    "loss, acc =model.evaluate(x_test, y_test)\n",
    "print(f\"체크포인트 로드전 : loss: {loss:3f}, acc{acc:3f}\")\n",
    "\n",
    "#체크포인트 파일을 모델에 로드\n",
    "model.load_weights(\"tmp_checkpoint.ckpt\")\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"체크포인트 로드후 : loss: {loss:3f}, acc{acc:3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1091a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 조기 종료\n",
    "\n",
    "tensorflow.keras.callbacks.EarlyStopping() 객체로 생성하며 모델 훈련 시 patience에 \n",
    "지정된 epoch 안에 손실이 줄어들지 않는다면 모델 훈련은 조기 종료한다\n",
    "다음은 조기 종료 기준으로 되는 지표를 검증 손실로 설정하고, patience =3 으로 설정해 \n",
    "조기 종료 콜백을 생성한다 \n",
    "따라서 3 epoch 동안 손실이 줄어들지 않으면 모델 훈련이 종료된다\n",
    "\"\"\"\n",
    "# 모델 인스턴스 생성\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    # 노드=10개가 되어야 한다\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "#모델 컴파일\n",
    "model.compile(optimizer = \"adam\", loss=\"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "# EarlyStopping 콜백 생성\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a191aca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2315 - accuracy: 0.9304 - val_loss: 0.1204 - val_accuracy: 0.9646\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0954 - accuracy: 0.9711 - val_loss: 0.0854 - val_accuracy: 0.9740\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0648 - accuracy: 0.9797 - val_loss: 0.0757 - val_accuracy: 0.9765\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0498 - accuracy: 0.9839 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0391 - accuracy: 0.9871 - val_loss: 0.0800 - val_accuracy: 0.9776\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 0.0761 - val_accuracy: 0.9772\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.0775 - val_accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bcba81dd60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "모델 체크포인트 콜백과 마찬가지로, 조기 종료 콜백 또한 모델을 훈련하는 fit()메소드 안에\n",
    "callbacks 매개변수로 지정한다\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train,\n",
    "         validation_data = (x_test, y_test),\n",
    "         epochs=20,\n",
    "         callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c874a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "val_loss 의 변화를 기준으로, 조기종료 콜백이 작동 \n",
    "조기종료 콜백에서 검증 손실 기준 3 epoch 동안 개선이 일어나지 않으면 조기 종료하는 규칙에\n",
    "걸려 훈련을 조기 종료 했다\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d80de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 학습률 스케줄러 \n",
    "tensorflow.keras.callback.LearningRateScheduler() 객체로 생성하여 훈련에 대한 학습률 조정한다.\n",
    "학습률을 특징 로직에 의하여 제어하고자 할 때 로직을 함수로 구현한 뒤 LearningRateScheduler 객체에 적용해 주면 된다\n",
    "\n",
    "다음은 5 epoch 동안 학습률을 유지하되 6 epoch부터는 학습률을 점차 감소시키는 예\n",
    "\"\"\"\n",
    "def scheduler(epoch, lr):\n",
    "    tf.print(f\"learning_rate:{lr:5f}\")\n",
    "    #첫 5 epoch동안 유지\n",
    "    if epoch < 5 :\n",
    "        return lr\n",
    "    else:\n",
    "        #학습률 감소 적용\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "    #콜백 객체 생성 및 scheduler 함수 적용\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18442ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "\"\"\"모델 인스턴스를 다시 생성하고 컴파일\n",
    "초기 학습률을 출력하여 확인 \"\"\"\n",
    "# 모델 인스턴스 생성\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    # 노드=10개가 되어야 한다\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "#모델 컴파일 - 학습률 스케줄러 \n",
    "model.compile(tf.keras.optimizers.SGD(), loss=\"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "#초기 학습률 확인(0.01)\n",
    "print(round(model.optimizer.lr.numpy(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba5fd692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate:0.010000\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6563 - accuracy: 0.8175 - val_loss: 0.3002 - val_accuracy: 0.9136 - lr: 0.0100\n",
      "learning_rate:0.010000\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2715 - accuracy: 0.9222 - val_loss: 0.2321 - val_accuracy: 0.9315 - lr: 0.0100\n",
      "learning_rate:0.010000\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2107 - accuracy: 0.9395 - val_loss: 0.1900 - val_accuracy: 0.9451 - lr: 0.0100\n",
      "learning_rate:0.010000\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1725 - accuracy: 0.9506 - val_loss: 0.1714 - val_accuracy: 0.9484 - lr: 0.0100\n",
      "learning_rate:0.010000\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1457 - accuracy: 0.9571 - val_loss: 0.1416 - val_accuracy: 0.9571 - lr: 0.0100\n",
      "learning_rate:0.010000\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1245 - accuracy: 0.9638 - val_loss: 0.1362 - val_accuracy: 0.9602 - lr: 0.0090\n",
      "learning_rate:0.009048\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1094 - accuracy: 0.9690 - val_loss: 0.1155 - val_accuracy: 0.9657 - lr: 0.0082\n",
      "learning_rate:0.008187\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0980 - accuracy: 0.9717 - val_loss: 0.1116 - val_accuracy: 0.9667 - lr: 0.0074\n",
      "learning_rate:0.007408\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0890 - accuracy: 0.9747 - val_loss: 0.1060 - val_accuracy: 0.9684 - lr: 0.0067\n",
      "learning_rate:0.006703\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0816 - accuracy: 0.9766 - val_loss: 0.1005 - val_accuracy: 0.9690 - lr: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00607"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "schedulere 함수에 적용하고자 하는 학습률 감소 로직을 구현한뒤 LearningRateScheduler 객체에 적용\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train,\n",
    "         validation_data=(x_test, y_test),\n",
    "         epochs=10,\n",
    "         # 학습률 스케줄러 적용\n",
    "         callbacks=[lr_scheduler]\n",
    "         )\n",
    "\n",
    "#최종 학습률 스케줄러 확인\n",
    "round(model.optimizer.lr.numpy(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6bdddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "학습률이 감소하여 10epoch 훈련이 완료된 후에는 최종 학습률이 0.00607로 감소한 것을 확인 할 수 있다\n",
    "scheduler 함수에 구현한 로직을 수정하여 학습률 감소 크기나 시점을 다르게 하여 적용할 수 있다\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6498ca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6318 - accuracy: 0.8273 - val_loss: 0.2952 - val_accuracy: 0.9131\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2630 - accuracy: 0.9247 - val_loss: 0.2331 - val_accuracy: 0.9300\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2042 - accuracy: 0.9413 - val_loss: 0.1825 - val_accuracy: 0.9480\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1669 - accuracy: 0.9525 - val_loss: 0.1549 - val_accuracy: 0.9566\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1402 - accuracy: 0.9599 - val_loss: 0.1395 - val_accuracy: 0.9610\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1204 - accuracy: 0.9654 - val_loss: 0.1190 - val_accuracy: 0.9651\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1046 - accuracy: 0.9700 - val_loss: 0.1104 - val_accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0928 - accuracy: 0.9735 - val_loss: 0.1054 - val_accuracy: 0.9668\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0827 - accuracy: 0.9764 - val_loss: 0.0950 - val_accuracy: 0.9697\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0736 - accuracy: 0.9792 - val_loss: 0.0922 - val_accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bc83017160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#텐서보드\n",
    "텐서보드는 훈련에 대한 시각화를 실시간으로 제공하는 유용한 도구\n",
    "시각화 라이브러리인 matplotlib이나 seaborn으로 epoch 별 손실과 정확도 등의 평가지표를 \n",
    "시각화하는 방법으로 History객체를 활용하는 예제를 앞에서 소개한 바 있다\n",
    "텐서보드를 활용하면 epoch별 훈련 손실 및 평가 지표를 시각화해 차트로 보여주는 것은 물론이고,\n",
    "모델의 구조를 시각화해 보여주거나 레이어의 가중치 분포도를 시각화로 제공한다\n",
    "또한 모델 훈련시 시각화 차트를 실시간으로 업데이트해 제공하는 기능도 포함\n",
    "\n",
    "\n",
    "텐서보드 시각화를 위해서는 tensorflow.keras.callbacks.TesorBoard() 객체로 생성하여\n",
    "콜백 매개변수에 적용하면 된다. 가중치 초기화를 위해 모델 인스턴스를 다시 만들어 주는 점에 유의\n",
    "\"\"\"\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    # 노드=10개가 되어야 한다\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "#모델 컴파일 - 학습률 스케줄러 \n",
    "model.compile(tf.keras.optimizers.SGD(), loss=\"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "#텐서보드 저장 경로 지정\n",
    "log_dir = \"tensorboard\"\n",
    "\n",
    "#텐서보드 콜백 정의\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "         validation_data=(x_test, y_test),\n",
    "         epochs=10,\n",
    "         callbacks =[tensorboard],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "005548e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-126b89536a275bac\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-126b89536a275bac\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "훈련이 완료된 후 노트북의 매직 커멘드를 입력하여 텐서보드를 바로 출력\n",
    "\"\"\"\n",
    "#텐서보드 extension로드\n",
    "%load_ext tensorboard\n",
    "\n",
    "#텐서보드 출력 매직 커멘드\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dbc06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
