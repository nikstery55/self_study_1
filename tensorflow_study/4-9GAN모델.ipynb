{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db15bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GAN 모델 - 생성적 적대 신경망\n",
    "\n",
    "\"생성적\"이라는 것은 Generator(생성자)가 학습에 필요한 데이터를 만드는 것을 나타내고\n",
    "\"적대적\"이라는 것은 만들어지는 데이터가 Discriminator (판별자)를 속이기 위한 가짜이기 때문이라고 해석할 수 있다\n",
    "\n",
    "GAN은 다음과 같이 위조지폐를 만든 범죄자와 경찰 관계를 비유하여 설명한다\n",
    "즉 범죄자는 위조지폐를 만들고, 경찰은 위조지폐를 판별해서 범죄자를 찾는다 \n",
    "이렇게 2개의 모델이 서로 상대적으로 다른 목적을 가지고 경쟁하면서 서로를 발전시킨다\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7787537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 파라미터 설정\n",
    "img_shape = (28, 28, 1)\n",
    "z_dim = 100\n",
    "row_num = 8\n",
    "col_num = 8\n",
    "batch_size = row_num * col_num\n",
    "\n",
    "epoch_num = 10\n",
    "learning_rate = 0.0001\n",
    "class_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae7787b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "실습에 사용할 mnist 데이터셋을 불러옴 \n",
    "정규화하고 shape을 바꿔준다\n",
    "\"\"\"\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba635ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1024)             4096      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,078,017\n",
      "Trainable params: 1,075,969\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "판별자(경찰) 역할을 하는 Discriminator 모델을 정의한다\n",
    "모델은 (28, 28, 1)이미지를 입력 받아서, 진짜인지 가짜인지 판별하는 이진 분류 작업을 수행\n",
    "\"\"\"\n",
    "i = tf.keras.Input(shape=img_shape)\n",
    "out = tf.keras.layers.Conv2D(16, 3, 2, padding=\"same\")(i)\n",
    "out = tf.keras.layers.Conv2D(32, 3, 2, padding=\"same\")(out)\n",
    "out = tf.keras.layers.Conv2D(64, 3, 2, padding=\"same\")(out)\n",
    "out = tf.keras.layers.Flatten()(out)\n",
    "out = tf.keras.layers.BatchNormalization()(out)\n",
    "out = tf.keras.layers.Dense(1024, activation=\"tanh\")(out)\n",
    "out = tf.keras.layers.Dense(1, activation=\"sigmoid\")(out)\n",
    "d_model = tf.keras.Model(inputs=[i], outputs=[out])\n",
    "\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c44ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              103424    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              1607200   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1568)             6272      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 16)       4624      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 1)        145       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,721,665\n",
      "Trainable params: 1,718,529\n",
      "Non-trainable params: 3,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "이번에는 생성자(범죄자) 역할을 하는 Generator 모델을 정의한다\n",
    "이 모델은 (28, 28, 1) 이미지를 입력받아서, 진짜인지 가짜인지 판별하는 이진 분류 작업을 수행한다\n",
    "\n",
    "\"\"\"\n",
    "i = tf.keras.Input(shape=(z_dim))\n",
    "out = tf.keras.layers.Dense(1024, activation=\"tanh\")(i)\n",
    "out = tf.keras.layers.Dense(7 * 7 * 32, activation=\"tanh\")(out)\n",
    "out = tf.keras.layers.BatchNormalization()(out)\n",
    "out = tf.keras.layers.Reshape((7, 7, 32))(out)\n",
    "out = tf.keras.layers.Conv2DTranspose(16, 3, 2, padding=\"same\")(out)\n",
    "out = tf.keras.layers.Conv2DTranspose(1, 3, 2, padding=\"same\")(out)\n",
    "out = tf.keras.layers.Activation(\"sigmoid\")(out)\n",
    "g_model = tf.keras.Model(inputs=[i], outputs=[out])\n",
    "\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a954cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "옵티마이저와 Discriminator 이진 분류에 맞는 손실함수로 BinaryCrossentropy를 설정한다\n",
    "\"\"\"\n",
    "#옵티마이저 \n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "#Discrimininator 손실함수\n",
    "d_loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8478327e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae623c60b1340d6ad7a063cb598dcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4bb12d0abf49dcbbf347b6a03fbf84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9192033e3b6d49c88c1d0f612d86f3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f5fbc68b2648a6a783856487cf39e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ea6542727c49739dfc95d935091c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e918cb5bef3f436296277d5866b6c812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d2b9ec497742e5825b1ea33ea682f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb78ede87e164be0aa7f60ab106a8dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e40a355b0404bb8a0a6e85fbdc54903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2141799ee74438b12046e6a51ad729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 완료\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "모델을 학습하면서 동영상으로 저장할 수 있도록 설정한다\n",
    "모델 학습과정은 다음과 같이 진행 된다\n",
    "\n",
    "1 - Generator가 batch size 만큼 가짜 Data를 생성한다\n",
    "2 - 가짜 Data를 0 으로 판단하도록 Discriminator를 학습한다\n",
    "3 - 진짜 Data를 1 로 판단하도록 Discriminator를 학습한다\n",
    "4 - Generator가 만든 가짜 Data를 Discriminator 가 진짜라고 판단하도록 Generator를 학습한다\n",
    "\"\"\"\n",
    "fcc=cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out=cv2.VideoWriter('hjk_gan_mnist.avi', fcc, 1.0, (28*row_num, 28 * col_num))\n",
    "\n",
    "# 1 Epoch에 batch size를 고려하여 학습할 수를 구한다.\n",
    "batch_count =x_train.shape[0]//batch_size\n",
    "\n",
    "for e in range(epoch_num):\n",
    "    for _ in tqdm(range(batch_count)):\n",
    "        \n",
    "        #경찰(Discriminator) 학습\n",
    "        # z는 Noise 또는 Latent Vector라 불리우는 값이다.\n",
    "        # 위조지폐(Fake Image)를 만드는 재료라고 생각하자. \n",
    "        z = np.random.uniform(-1.0, 1.0, (batch_size, z_dim))\n",
    "        # 재료(z)를 가지고 가짜 이미지를 만든다.\n",
    "        # 그리고 가짜(0)라고 라벨을 만들자\n",
    "        f_img = g_model.predict(z)   #### fake_img 가짜 데이터 를 사용\n",
    "        f_label = np.zeros((batch_size, 1))  #####  0으로 라벨링\n",
    "        \n",
    "        # Gradient Tape를 그리고,  Discriminator Loss(binary cross entropy)를\n",
    "        # 이용하여 위조지폐(Fake Image)는 가짜(0)라고 Discriminator를 학습하자\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = d_model(f_img)\n",
    "            loss = d_loss(f_label, pred)\n",
    "        vars = d_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))\n",
    "        \n",
    "        # x_train에서 랜덤하게 batch size만큼 데이터를 가지고 온다.\n",
    "        # 그리고 진짜(1)이라고 라벨을 만든다.\n",
    "        batch_num=np.random.randint(0,  x_train.shape[0],  size=batch_size)\n",
    "        r_img = x_train[batch_num]    ## real_img 진짜 데이터 x_train을 사용 \n",
    "        r_label = np.ones((batch_size, 1))    ### 1으로 라벨링\n",
    "        \n",
    "        # Gradient Tape를 그리고,  Discriminator Loss(binary cross entropy)를\n",
    "        # 이용하여 진짜 지폐(Real Image)는 진짜(1)라고 Discriminator를 학습하자\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = d_model(r_img)\n",
    "            loss = d_loss(r_label, pred)\n",
    "        vars = d_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))\n",
    "\n",
    "        # 이번엔 위조지폐범(Generator)를 학습해보자\n",
    "        # Gradient Tape를 그리고,  Discriminator Loss(binary cross entropy)를\n",
    "        # 이용하여 가짜 지폐(Real Image)는 진짜(1)라고 Discriminator에게 속인다.\n",
    "        # 그리고 Discriminator가 틀리다고 생각되는 부분을 \n",
    "        # 위조지폐범에게 정보를 전달하여 그부분을 수정하도록 한다.\n",
    "        with tf.GradientTape() as tape:\n",
    "            f_img = g_model(z)\n",
    "            pred = d_model(f_img)\n",
    "            loss = d_loss(r_label, pred) \n",
    "        vars = g_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))     \n",
    "        \n",
    "        # 학습 시 마다 중간 결과를 이미지로 만들고,  이미지를 붙여 동영상으로 저정하자.\n",
    "        sample_img = np.zeros((28*row_num, 28 * col_num))\n",
    "        f_img = np.resize(f_img, (row_num, col_num, 28, 28))\n",
    "        for i in range(row_num):\n",
    "            for j in range(col_num):\n",
    "                sample_img[i * 28:i * 28 +28, j * 28:j * 28 +28] = f_img[i, j, :, :]\n",
    "        sample_img = np.uint8(sample_img * 255.)\n",
    "        sample_img = cv2.applyColorMap(sample_img, cv2.COLORMAP_HOT)\n",
    "        out.write(sample_img)\n",
    "    \n",
    "    print(e, \"완료\")\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e6bf215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5779739784409cbb533bc29af40f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757162bc5c36425aa455aabc879de719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c05ddc0af2417d915fd5355b0e65a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0f760837454f78b2f4e46814c6d511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b397df7394a4ef38f96809ed72e0c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0f5af59e8b4cc489ca533ecf05b206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1c4bb696e9490abeff43044aba2011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7bcab445d543cb9e3db6ce927a4859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f376796880a4ec5aa737abef7031b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac50e9d76fd546baa9a2a49433646cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 완료\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "앞에서 만든 GAN 구조로는 만들어지는 가짜 데이터를 조정할 수가 없다. 다시 말하면, \n",
    "생성되는 이미지와 실제 정답 레이블과 관계가 없다. Generator가 생성하는 가짜 이미지가 원래 정답 레이블을\n",
    "나타낼 수 있도록 하기 위해,\n",
    "One-Hot Encoding으로 레이블 값(l_i)을 Generator와 Discriminator의 입력으로 추가한다\n",
    "\"\"\"\n",
    "#Conditional GAN\n",
    "\n",
    "# Label을 입력값으로 받을 수 있도록 Discriminator 모델 수정\n",
    "i = tf.keras.Input(shape=img_shape)\n",
    "l_i = tf.keras.Input(shape=(1, ), dtype=tf.int32)\n",
    "l_out = tf.one_hot(l_i, class_num)\n",
    "l_out = tf.keras.layers.Dense(28*28*1)(l_out)\n",
    "l_out = tf.keras.layers.Reshape((28, 28, 1))(l_out) \n",
    "out = tf.keras.layers.Add()([i, l_out])\n",
    "out = tf.keras.layers.Conv2D(16, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Conv2D(32, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Conv2D(64, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Flatten()(out)\n",
    "out = tf.keras.layers.BatchNormalization()(out)\n",
    "out = tf.keras.layers.Dense(1024, activation='tanh')(out)\n",
    "out = tf.keras.layers.Dense(1, activation='sigmoid')(out)\n",
    "d_model = tf.keras.Model(inputs=[i, l_i],  outputs=[out])\n",
    "\n",
    "# Label을 입력값으로 받을 수 있도록 Generator모델 수정\n",
    "i=tf.keras.Input(shape=(z_dim, ))\n",
    "l_i = tf.keras.Input(shape=(1, ), dtype=tf.int32)\n",
    "l_out = tf.one_hot(l_i, class_num)\n",
    "l_out = tf.keras.layers.Dense(z_dim)(l_out)\n",
    "l_out = tf.keras.layers.Reshape((z_dim, ))(l_out) \n",
    "out = tf.keras.layers.Add()([i, l_out])\n",
    "out = tf.keras.layers.Dense(1024, activation='tanh')(out)\n",
    "out = tf.keras.layers.Dense(7*7*32, activation='tanh')(out)\n",
    "out = tf.keras.layers.BatchNormalization()(out)\n",
    "out = tf.keras.layers.Reshape((7, 7, 32))(out)\n",
    "out = tf.keras.layers.Conv2DTranspose(16, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Conv2DTranspose(1, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Activation('sigmoid')(out)\n",
    "g_model = tf.keras.Model(inputs=[i, l_i],  outputs=[out])\n",
    "\n",
    "# Data를 생성하고 판단할 때 Label 값을 받도록 수정 \n",
    "fcc=cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out=cv2.VideoWriter('cgan_mnist.avi', fcc, 10.0, (28*row_num, 28 * col_num))\n",
    "\n",
    "batch_count =x_train.shape[0]//batch_size\n",
    "\n",
    "for e in range(epoch_num):\n",
    "    for _ in tqdm(range(batch_count)):\n",
    "        \n",
    "        # f_y값은 0~9까지 임의값을 원핫 인코딩한 값이다.\n",
    "        # f_y값도 Ganerator의 인풋값으로 추가하자\n",
    "        z = np.random.uniform(-1.0, 1.0, (batch_size, z_dim))\n",
    "        f_y = np.random.randint(0, class_num, size=batch_size)\n",
    "        f_y = np.reshape(f_y, (batch_size, 1))\n",
    "        f_img = g_model.predict([z, f_y])\n",
    "        f_label = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # 위조지폐(Fake Image)와 라벨 모두를 인풋으로 받아서\n",
    "        # 가짜라고 학습한다.\n",
    "        # 예를 들어 5000원짜리 위조지폐라고 학습한다. \n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = d_model([f_img, f_y])\n",
    "            loss = d_loss(f_label, pred)\n",
    "        vars = d_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))\n",
    "        \n",
    "        # 실제지폐(Real Image)와 라벨 모두를 인풋으로 받아서\n",
    "        # 진짜라고 학습한다.\n",
    "        # 예를 들어 5000원짜리 진짜 지폐라고 학습한다. \n",
    "        batch_num=np.random.randint(0, x_train.shape[0], size=batch_size)\n",
    "        r_img = x_train[batch_num]\n",
    "        r_y = y_train[batch_num]\n",
    "        r_label = np.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = d_model([r_img, r_y])\n",
    "            loss = d_loss(r_label, pred)\n",
    "        vars = d_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))\n",
    "\n",
    "        f_y=[i%class_num for i in range(batch_size)]\n",
    "        f_y = np.reshape(f_y, (batch_size, 1))\n",
    "\n",
    "        # 이제 가짜 지폐와 가짜 라벨을 경찰에게 보여주고\n",
    "        # 이 지폐가 진짜라고 학습하고,  그 차이점을 위조지폐범에게 알려준다.\n",
    "        # 그리고 위조지폐범은 그 차이를 수정해 나간다.\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            f_img = g_model([z, f_y])\n",
    "            pred = d_model([f_img, f_y])\n",
    "            loss = d_loss(r_label, pred)\n",
    "        vars = g_model.trainable_variables\n",
    "        grad = tape.gradient(loss,  vars)\n",
    "        opt.apply_gradients(zip(grad,  vars))     \n",
    "        \n",
    "        sample_img = np.zeros((28*row_num, 28 * col_num))\n",
    "        f_img = np.resize(f_img, (row_num, col_num, 28, 28))\n",
    "        for i in range(row_num):\n",
    "            for j in range(col_num):\n",
    "                sample_img[i * 28:i * 28 +28, j * 28:j * 28 +28] = f_img[i, j, :, :]\n",
    "        sample_img = np.uint8(sample_img * 255.)\n",
    "        sample_img = cv2.applyColorMap(sample_img, cv2.COLORMAP_HOT)\n",
    "        out.write(sample_img)\n",
    "    \n",
    "    print(e, \"완료\")\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731e3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13d13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367b16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa9d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
