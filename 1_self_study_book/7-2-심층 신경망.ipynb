{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761e4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 심층 신경망\n",
    "\n",
    "-2개의 층\n",
    "케라스 API를 사용해서 패션 MNIST 데이터셋 불러오기\n",
    "\"\"\"\n",
    "from tensorflow import keras\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc048a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "이미지의 픽셀값을 0~255 범위에서 0~1 사이로 변환하고\n",
    "28X28 크기의 2차원 배열을 784 크기의 1차원 배열로 바꿈\n",
    "사이킷런의 train_test_split()함수로 훈련세트와 검증세트 나눔\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled = train_scaled.reshape(-1, 28*28)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b7c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "인공 신경망 모델에 층을 2개 추가함\n",
    "\n",
    "이렇게 입력층과 출력층 사이에 있는 모든 층을 은닉층 이라고 함\n",
    "\n",
    "활성화 함수 - 신경망 층의 선형 방정식의 계산 값에 적용하는 함수\n",
    "\n",
    "출력층에 적용했던 소프트맥스 함수도 활성화 함수입니다 \n",
    "출력층에 적용하는 활성화 함수는 종류가 제한 되어 있다\n",
    "이진 분류일 경우 시그모이드 함수, 다중 분류일 경우 소프트맥스 함수\n",
    "은닉층의 활성화 함수는 비교적 자유롭습니다\n",
    "대표적으로 시그모이드 함수와 렐루 함수 \n",
    "\n",
    "책 읽어 보자 - 선형 계산을 적당하게 비선형적으로 비틀어 주어야합니다\n",
    "\n",
    "모든 신경망의 은닉층에는 항상 활성화 함수가 있다\n",
    "\n",
    "시그모이드 활성화 함수를 사용한 은닉층과 소프트맥스 함수를 사용한 출력층을 \n",
    "케라스의 Dense 클래스로 만들어 봄\n",
    "케라스에서 신경망의 첫 번째 층은 input_shape 매개변수로 입력의 크기를 꼭 지정해야함\n",
    "\n",
    "---\n",
    "dense1 은닉층이고 100개의 뉴런을 가진 밀지브\n",
    "활성화 함수는 sigmoid로 지정  input_shape 매개변수에서 입력의 크기 (784)로 지정\n",
    "은닉층의 뉴런 개수를 정하는 데는 특별한 기준이 없다 \n",
    "- 몇 개의 뉴런을 두어야 할지 판단하기 위해서는 상당한 경험이 필요함\n",
    "\n",
    "\"\"\"\n",
    "dense1 = keras.layers.Dense(100, activation=\"sigmoid\", input_shape=(784,))\n",
    "dense2 = keras.layers.Dense(10, activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cdc6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-심층 신경망 만들기\n",
    "\n",
    "dense1과 dense2 객체를 Sequential 클래스에 추가하여 심층 신경망 만들기\n",
    "\"\"\"\n",
    "model = keras.Sequential([dense1, dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b735ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sequential 클래스의 객체를 만들 때 여러 개의 층을 추가하려면 이와 같이 dense1과 dense2를 리스트로 만들어 전달\n",
    "출력층을 가장 마지막에 두어야함\n",
    "인공 신경망의 강력한 성능은 바로 이렇게 층을 추가하여 입력 데이터에 대해 \n",
    "연속적인 학습을 진행하는 능력\n",
    "\n",
    "케라스 모델의 summary()메서드 호출\n",
    "\n",
    "출력의 크기를 보면 (None,100)임 \n",
    "첫 번째 차원은 샘플의 개수를 나타냄 - 샘플 개수가 아직 정의되어 있지 않기 때문에 None\n",
    "왜그럴까? - 케라스 모델의 fit()메서드에 훈련 데이터를 주입하면 이 데이터를 한 번에 모두 사용하지 않고\n",
    "잘게 나누어 여러 번에 걸쳐 경사 하강법 단계를 수행함, 바로 미니배치 경사 하강법을 사용\n",
    "\n",
    "케라스의 기본 미니배치 크기는 32개입니다. 이 값은 fit()메서드에서 batch_size 매개변수로 바꿀 수 있다\n",
    "따라서 샘플 개수를 고정하지 않고 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정\n",
    "이렇게 신경망 층에 입력되거나 출력되는 배열의 첫 번째 차원을 배치 차원이라고 부름\n",
    "\n",
    "두 번째 100, 은닉층의 뉴런 개수를 100개로 두었으니까 100개의 출력이 나옴\n",
    "즉 샘플마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축\n",
    "\n",
    "마지막에 모델 파라미터 개수가 출력됨\n",
    "이 층은 Dense 층이므로 입력 픽셀 784개와 100개의 모든 조합에 대한 가중치가 있다\n",
    "첫층은 784개 X 100개 + 100개 = 78500개\n",
    "두 번째층은 100개 X 10개 + 10개 = 1010개\n",
    "총 모델 파라미터 개수와 훈련되는 파라미터 개수가 동일하게 79510개 \n",
    "\n",
    "은닉층ㅇ과 출력층의 파라미터 개수를 합친 값\n",
    "\n",
    "그 아래 훈련되지 않는 파라미터(Non-trainable params)는 0 으로 나옴\n",
    "\"\"\"\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f372d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 층을 추가하는 다른방법\n",
    "모델을 훈련하기 전에 Seqeuntial 클래스에 층을 추가하는 다른 방법\n",
    "\n",
    "Sequential 클래스의 생성자 안에서 바로 Dense 클래스의 객체를 만드는 경우가 많다\n",
    "\"\"\"\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"sigmoid\", input_shape=(784,),\n",
    "                      name=\"hidden\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", name=\"output\")\n",
    "], name=\"패션 MNIST 모델\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9e2228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST 모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sequential 클래스의 name 매개변수로 모델의 이름을 지정\n",
    "Dense층의 name 매개변수에 층의 이름을 hidden과 output으로 각각 지정\n",
    "\n",
    "모델의 이름과 달리 층의 이름은 반드시 영문이어야함\n",
    "summary()메서드 출력\n",
    "\"\"\"\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a7edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "이 방법이 편리하지만 아주 많은 층을 추가하려면 Sequential 클래스 생성자가 매우 길어짐\n",
    "또 조건에 따라 층을 추가할 수도 없다\n",
    "Sequential 클래스에서 층을 추가할 때 가장 널리 사용하는 방법은 모델의 add()메서드\n",
    "\n",
    "이 방법은 Sequential 클래스의 객체를 만들고 이 객체의 add()메서드를 호출하여 층을 추가\n",
    "\"\"\"\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation=\"sigmoid\", input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be5fc539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "summary()메서드\n",
    "\"\"\"\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e4e26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5667 - accuracy: 0.8072\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4064 - accuracy: 0.8542\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3711 - accuracy: 0.8666\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3473 - accuracy: 0.8745\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3308 - accuracy: 0.8803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e77aa9970>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "모델을 훈련\n",
    "compile()메서드 사용\n",
    "에포트 5번\n",
    "\\\\\n",
    "그리고 활성화 함수에 알아보자\n",
    "\"\"\"\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53a247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 렐루 함수\n",
    "- 렐루 함수는 심층 신경망에 좋다\n",
    "렐루 함수는 입력이 양수일 경우 마치 활성화 함수가 없는 것처럼 그냥 입력을 \n",
    "통과시키고 음수일 경우에는 0으로 만듬\n",
    "\n",
    "렐수 함수는 특히 이미지 처리에 좋은 성능을 낸다\n",
    "\n",
    "1차원으로 펼쳐주는 방법- 케라스에서는 Flatten 층이 있다\n",
    "Flatten 클래스는 배치 차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼치는 역할만 함\n",
    "Flatten 클래스를 층처럼 입력층과 은닉층 사이에 추가하기 때문에 이를 층이라고 부름\n",
    "\"\"\"\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c123bfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "첫 번쨰 Dense층에 있던 input_shape 매개변수를 Flatten 층으로 옮김\n",
    "첫 번째 Dense층의 활성화 함수를 relu로 변경\n",
    "summary()호출\n",
    "\"\"\"\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5edd81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "훈련 데이터 다시 준비해서 모델에 훈련\n",
    "\"\"\"\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6e24053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5291 - accuracy: 0.8121\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3905 - accuracy: 0.8600\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3524 - accuracy: 0.8739\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3337 - accuracy: 0.8804\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3168 - accuracy: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e89d94be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "모델 컴파일하고 훈련\n",
    "\n",
    "시그모디으 함수를 사용했을 때와 비교하면 성능이 조금 향상됨\n",
    "\"\"\"\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ba7d756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3574 - accuracy: 0.8809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3573974668979645, 0.8809166550636292]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "검증 세트에서의 성능 확인\n",
    "인공 신경망의 하이퍼파라미터에 알아보자\n",
    "\"\"\"\n",
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e8a5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-옵티마이저\n",
    "\n",
    "신경망에는 특히 하이퍼파라미터가 많다 - 은닉층의 개수, 뉴런 개수, 활성화 함수, 층의 종류, 배치 사이즈 매개변수, 에포크 등등\n",
    "\n",
    "마지막으로 compile()메서드에서는 케라스의 기본 경사 하강법 알고리즘인 RMSprop을 사용함\n",
    "케라스는 다양한 종류의 경사 하강법 알고리즘을 제공함 - 이를 옵티마이저 \n",
    "\n",
    "가장 기본적인 옵티마이저는 확률적 경사 하강법인 SGD\n",
    "\n",
    "SGD옵티마이저를 사용하려면 compile()메서드의 optimizer 매개변수를 \"sgd\"로 지정\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "\n",
    "만약 SGD클래스의 학습률 기본값이 0.01 일때 이를 바꾸고 싶다면 \n",
    "원하는 학습률을 learning_rate 매개변수에 지정하여 사용\n",
    "\n",
    "sgd = keras.optimizers.SGD(learning_rate = 0.1)\n",
    "\n",
    "기본 경사 하강법 옵티마이저는 모두 SGD 클래스에서 제공 \n",
    "SGD 클래스의 momentum 매개변수의 기본값은 0\n",
    "이를 0 보다 큰 값으로 지정하면 마치 이전의 그레이디언트를 가속도 처럼 사용하는 - 모멘텀 최적화를 사용함\n",
    "보통 momentum 매개변수는 0.9 이상을 지정\n",
    "\n",
    "SGD 클래스의 nesterov 매개변수를 기본값 false 에서 True 로 바꾸면 - 네스테로프 모멘텀 최적화 를 사용함\n",
    "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "\n",
    "네스테로프 모멘텀은 모멘텀 최적화를 2번 반복하여 구현함\n",
    "대부분의 경우 네스테로프 모멘텀 최적화가 기본 확률적 경사 하강법보다 더 나은 성능을 제공\n",
    "\n",
    "모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있다 \n",
    "이렇게 하면 안정적으로 최적점에 수렴할 가능성이 높습니다 - 이런 학습률을 적응적 학습률 이라고 함\n",
    "\n",
    "적응적 학습률을 사용하는 대표적인 옵티마이저는 Adagrad와 RMSProp 임\n",
    "optimizer 매개변수의 기본값은 바로 \"rmsprop\"\n",
    "\n",
    "두 옵티마이저의 매개변수를 바꾸고 싶다면 SGD와 같이 Adagrad와 RMSprop 클래스 객체를 만들어 사용\n",
    "\n",
    "adagrad = keras.optimizers.Adagrad()\n",
    "model.compile(optimizer=adagrad, loss=\"sprase_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "RMSprop 모습\n",
    "rmsprop = keras.optimizers.RMSprop()\n",
    "model.compile(optimizers=rmsprop, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "모멘텀 최적화와 RMSprop의 장점을 접목한 것이 Adam\n",
    "\n",
    "Adam 클래스의 매개변수 기본값을 사용해 패션 MNIST 모델을 훈련\n",
    "\n",
    "- 와 이렇게 중요한 옵티마이저 설명은 좋은데 한번 써먹으면 어떤지 \n",
    "\"\"\"\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fae58da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5209 - accuracy: 0.8183\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3925 - accuracy: 0.8593\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3500 - accuracy: 0.8738\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3239 - accuracy: 0.8828\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3079 - accuracy: 0.8871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13cc16425e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "compile()메서드의 optimizer를 \"adam\"으로 설정하고 5번 에포크\n",
    "\"\"\"\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bb65d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34397852420806885, 0.875]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "검증 세트 확인\n",
    "\"\"\"\n",
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880df79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
